import streamlit as st
import base64
from PIL import Image
import io
import time

# é¡µé¢é…ç½®
st.set_page_config(page_title="æ™šå¤œÂ·é»„é‡‘ETFå†³ç­–ç³»ç»Ÿ (V7.1å…¼å®¹ç‰ˆ)", layout="wide")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ æ ¸å¿ƒè®¾ç½®")
    model_provider = st.radio("é€‰æ‹© AI å¼•æ“:", ["Google Gemini (å…è´¹)", "OpenAI GPT-4o (ä»˜è´¹)"])
    api_key = st.text_input(f"è¾“å…¥ {model_provider.split()[0]} API Key", type="password")
    st.info("ğŸ’¡ å¦‚æœ Gemini æŠ¥é”™ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å°è¯•åˆ‡æ¢ä¸åŒç‰ˆæœ¬çš„æ¨¡å‹ã€‚")

st.title("ğŸ›ï¸ é»„é‡‘ ETF æ·±åº¦å†³ç­–ç³»ç»Ÿ (V7.1 è‡ªåŠ¨çº é”™ç‰ˆ)")
st.caption(f"å½“å‰å¼•æ“: {model_provider} | è‡ªåŠ¨é€‚é…æ¨¡å‹ç‰ˆæœ¬")

col1, col2 = st.columns([1.5, 1])

# ----------------- æ ¸å¿ƒé€»è¾‘ -----------------

def analyze_with_gemini_auto(image_bytes, key, prompt):
    import google.generativeai as genai
    
    genai.configure(api_key=key)
    
    # å¤‡é€‰æ¨¡å‹åˆ—è¡¨ï¼ˆAI ä¼šæŒ¨ä¸ªå°è¯•ï¼Œç›´åˆ°æˆåŠŸï¼‰
    candidate_models = [
        "gemini-1.5-flash",          # æœ€æ–°æ ‡å‡†å
        "gemini-1.5-flash-latest",   # åˆ«å1
        "gemini-1.5-flash-001",      # ç‰¹å®šç‰ˆæœ¬å·
        "gemini-1.5-pro",            # å¤‡ç”¨ï¼šProç‰ˆæœ¬
    ]
    
    image = Image.open(io.BytesIO(image_bytes))
    last_error = ""

    # å¾ªç¯å°è¯•
    for model_name in candidate_models:
        try:
            # åˆ›å»ºæ¨¡å‹å¯¹è±¡
            model = genai.GenerativeModel(model_name)
            # å°è¯•ç”Ÿæˆ
            response = model.generate_content([prompt, image])
            return f"âœ… æˆåŠŸè¿æ¥æ¨¡å‹: **{model_name}**\n\n" + response.text
        except Exception as e:
            last_error = str(e)
            continue # å¦‚æœå¤±è´¥ï¼Œå°è¯•åˆ—è¡¨é‡Œçš„ä¸‹ä¸€ä¸ª
            
    return f"âŒ æ‰€æœ‰æ¨¡å‹å°è¯•å‡å¤±è´¥ã€‚å¯èƒ½æ˜¯ Key æ— æ•ˆæˆ–åŒºåŸŸå—é™ã€‚\næœ€åä¸€æ¬¡æŠ¥é”™: {last_error}"

def analyze_with_openai(image_bytes, key, prompt):
    from openai import OpenAI
    client = OpenAI(api_key=key)
    base64_image = base64.b64encode(image_bytes).decode('utf-8')
    try:
        response = client.chat.completions.create(
            model="gpt-4o", 
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªé»„é‡‘äº¤æ˜“åˆ†æå¸ˆã€‚"},
                {"role": "user", "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                ]}
            ],
            max_tokens=1200
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ OpenAI è¿æ¥å¤±è´¥: {str(e)}"

# æç¤ºè¯
system_prompt = """
è¯·æ‰®æ¼”ä¸€ä½ç»“åˆäº†â€œæ™šå¤œåšä¸»â€è¶‹åŠ¿æˆ˜æ³•ä¸â€œåå°”è¡—é‡åŒ–â€å› å­çš„é»„é‡‘åˆ†æå¸ˆã€‚
é’ˆå¯¹ç”¨æˆ·çš„ ETF (æ— æ æ†) äº¤æ˜“éœ€æ±‚ï¼Œåˆ†æè¿™å¼  K çº¿å›¾ã€‚

ã€é‡ç‚¹åˆ†æç»´åº¦ã€‘ï¼š
1. **ç”»çº¿å®šä½**ï¼š
   - è¯†åˆ«å›¾ä¸­çš„ã€é€šé“ç»“æ„ã€‘ï¼šæ˜¯æ€¥æ¶¨çš„è“è‰²é€šé“ï¼Œè¿˜æ˜¯ç¨³æ¶¨çš„ç´«è‰²é€šé“ï¼Ÿ
   - æ‰¾å‡ºã€æ”¯æ’‘ä½ã€‘ï¼šå‰ä½æˆ– MA30 å‡çº¿åœ¨å“ªé‡Œï¼Ÿ
   
2. **é‡åŒ–æ’é›· (è‚‰çœ¼ç›²åŒº)**ï¼š
   - **ä¹–ç¦»ç‡é£é™©**ï¼šä»·æ ¼æ˜¯å¦åç¦» MA30 å¤ªè¿œï¼Ÿ(æš—ç¤ºå›è°ƒé£é™©)
   - **é¡¶èƒŒç¦»**ï¼šè§‚å¯Ÿ MACD/RSIï¼Œæ˜¯å¦æœ‰â€œä»·æ¶¨é‡ç¼©â€çš„è¯±å¤šè¿¹è±¡ï¼Ÿ
   - **å¸ƒæ—å¸¦**ï¼šæ˜¯å¦æåº¦æ”¶å£(å˜ç›˜å‰å…†)æˆ–å¼€å£è¿‡å¤§(è¶…ä¹°)ï¼Ÿ

3. **æ“ä½œæŒ‡ä»¤ (ETFä¸“å±)**ï¼š
   - ç»™å‡ºæ˜ç¡®å»ºè®®ï¼šã€ä¹°å…¥åŠä»“ã€‘ã€ã€æ»¡ä»“æŒæœ‰ã€‘ è¿˜æ˜¯ ã€æ­¢ç›ˆå‡ä»“ã€‘ï¼Ÿ
   - æé†’ï¼šå¦‚æœæ˜¯ ETFï¼Œè¶Šè·Œè¶Šè¡¥çš„â€œä¸‡é‡‘æ²¹â€ç‚¹ä½åœ¨å“ªé‡Œï¼ˆä¾‹å¦‚å¸ƒæ—ä¸‹è½¨ï¼‰ï¼Ÿ

è¯·ç”¨æ¸…æ™°çš„ Markdown æ ¼å¼è¾“å‡ºï¼ŒåŒ…å«ã€ğŸ‘ï¸ ç›²åŒºæ‰«æã€‘ã€ã€ğŸ“ å…³é”®ç‚¹ä½ã€‘å’Œã€ğŸ›¡ï¸ æ“ä½œç­–ç•¥ã€‘ã€‚
"""

# ----------------- ç•Œé¢äº¤äº’ -----------------
if api_key:
    with col1:
        uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šä¼  K çº¿å›¾", type=["jpg", "png", "jpeg"])
        if uploaded_file:
            st.image(uploaded_file, caption="å¾…åˆ†æç›˜é¢", use_column_width=True)
    
    with col2:
        if uploaded_file:
            st.subheader("ğŸ¤– AI åˆ†ææŠ¥å‘Š")
            img_bytes = uploaded_file.getvalue()
            
            if st.button("å¼€å§‹æ·±åº¦æ‰«æ", type="primary"):
                with st.spinner("æ­£åœ¨è‡ªåŠ¨å¯»æ‰¾å¯ç”¨çš„ Gemini æ¨¡å‹..."):
                    if "Gemini" in model_provider:
                        result = analyze_with_gemini_auto(img_bytes, api_key, system_prompt)
                    else:
                        result = analyze_with_openai(img_bytes, api_key, system_prompt)
                    
                    st.markdown(result)
                    st.success("åˆ†æå®Œæˆï¼")
else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹© AI å¼•æ“å¹¶è¾“å…¥ Key")
